{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot With Movie Dialog.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rainniee/Neural-Networks-AI/blob/master/Chatbot%20With%20Movie%20Dialog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "erQw73FM4WnE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Pre-trained Word Vectors"
      ]
    },
    {
      "metadata": {
        "id": "WkgKw36l3QUZ",
        "colab_type": "code",
        "outputId": "3c9edb69-adca-465f-f83d-9ee182532f0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "cell_type": "code",
      "source": [
        "# spaCy is a wonderful Python library for natural language processing \n",
        "# both to tokenize text (i.e., turn text into a list of words) and for its database of word vectors\n",
        "!pip install spacy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.0.18)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.16.2)\n",
            "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.35)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.1)\n",
            "Requirement already satisfied: thinc<6.13.0,>=6.12.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (6.12.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.9)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.18.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: regex==2018.01.10 in /usr/local/lib/python3.6/dist-packages (from spacy) (2018.1.10)\n",
            "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.10.11)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (4.28.1)\n",
            "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.9.0.1)\n",
            "Requirement already satisfied: six<2.0.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.11.0)\n",
            "Requirement already satisfied: msgpack-numpy<0.4.4 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.4.3.2)\n",
            "Requirement already satisfied: msgpack<0.6.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy) (0.5.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.3.9)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy) (0.9.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e1wmd0B946WW",
        "colab_type": "code",
        "outputId": "4da182fa-d7e1-46e7-a6bf-2a68f685f290",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "cell_type": "code",
      "source": [
        "# spaCy requires a \"model\" file, which is a bundle of statistical information that allows the library to parse text into words and parts of speech\n",
        "# While spaCy comes with a model when you install it, that model does not include word vectors, so you'll need to download a model that does include them. \n",
        "# For English, recommended one is en_core_web_lg\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_lg==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.0.0/en_core_web_lg-2.0.0.tar.gz#egg=en_core_web_lg==2.0.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.0.0/en_core_web_lg-2.0.0.tar.gz (852.3MB)\n",
            "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 852.3MB 50.8MB/s \n",
            "\u001b[?25hInstalling collected packages: en-core-web-lg\n",
            "  Running setup.py install for en-core-web-lg ... \u001b[?25ldone\n",
            "\u001b[?25hSuccessfully installed en-core-web-lg-2.0.0\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_lg -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en_core_web_lg\n",
            "\n",
            "    You can now load the model via spacy.load('en_core_web_lg')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zUPOWpB65Vxj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_lg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pPPYzSpT5djD",
        "colab_type": "code",
        "outputId": "57947408-05a0-48c0-922b-9cec4cfea4ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1042
        }
      },
      "cell_type": "code",
      "source": [
        "# able to look up the word vector for a particular word using spaCy:\n",
        "nlp.vocab['summarization'].vector"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.33014  , -0.24604  , -0.083086 , -0.17316  , -0.27574  ,\n",
              "        0.30908  ,  0.24861  ,  0.29057  ,  0.20428  , -0.9444   ,\n",
              "        0.095839 ,  0.21136  ,  0.11212  ,  0.028754 , -0.034047 ,\n",
              "        0.28768  , -0.14761  , -0.33668  , -0.47391  , -0.70142  ,\n",
              "       -0.10779  ,  0.42247  ,  0.27796  , -0.022983 ,  0.076136 ,\n",
              "        1.1443   ,  0.97622  ,  0.015171 , -0.069094 , -0.56979  ,\n",
              "        0.28381  ,  0.24827  ,  0.8933   ,  0.10587  , -0.39049  ,\n",
              "       -0.018418 , -0.0029734, -0.18025  , -0.24388  ,  0.084734 ,\n",
              "       -0.11058  , -0.17906  , -0.83465  ,  0.29406  ,  0.03161  ,\n",
              "       -0.16967  ,  0.50273  ,  0.12738  , -0.42268  , -0.036089 ,\n",
              "        0.046027 ,  0.26427  ,  0.2542   ,  0.49341  , -0.23321  ,\n",
              "        0.83422  , -0.84002  , -0.10217  ,  0.42499  , -0.34567  ,\n",
              "        0.17311  ,  0.79635  ,  0.30024  ,  0.47831  ,  0.64396  ,\n",
              "        0.041427 ,  0.039959 ,  0.40117  ,  0.21181  , -0.40258  ,\n",
              "       -0.70354  , -0.085231 ,  0.21149  , -0.35306  ,  0.14195  ,\n",
              "       -0.35548  ,  0.43053  , -0.024873 ,  0.2811   ,  0.55591  ,\n",
              "       -0.16745  ,  0.47736  ,  0.12676  , -0.57106  ,  0.26739  ,\n",
              "        0.17725  ,  0.057617 , -0.30923  , -0.5908   ,  0.20411  ,\n",
              "       -0.57657  , -0.01755  ,  0.28533  ,  0.15266  ,  0.41821  ,\n",
              "        0.45737  ,  0.21582  ,  0.10637  ,  0.6382   ,  0.070463 ,\n",
              "        0.074228 , -0.20656  , -0.15054  , -0.55371  ,  0.21177  ,\n",
              "       -2.2765   ,  0.50276  ,  0.29873  ,  0.975    ,  0.29517  ,\n",
              "       -0.1639   ,  0.26146  , -0.21017  ,  0.41998  , -0.66801  ,\n",
              "        0.18704  , -0.31064  ,  0.018732 , -0.54446  , -0.39892  ,\n",
              "       -0.58449  , -0.32172  ,  0.12517  ,  0.801    , -0.11517  ,\n",
              "       -0.043359 , -0.43723  ,  0.46296  ,  0.50546  ,  0.18782  ,\n",
              "        0.42452  , -0.36391  ,  0.75224  , -0.10613  ,  0.073755 ,\n",
              "       -0.10631  , -0.41274  , -0.20886  ,  0.63442  ,  0.57076  ,\n",
              "        0.96688  , -0.184    , -0.75011  , -0.20338  , -0.35707  ,\n",
              "       -0.29422  , -0.55583  , -0.42488  ,  0.55268  ,  0.50557  ,\n",
              "       -0.28107  , -0.3422   , -0.55874  , -0.071004 ,  0.48918  ,\n",
              "        0.48683  ,  0.2553   , -0.56176  , -0.15868  ,  0.029752 ,\n",
              "       -0.16368  , -0.25457  , -0.28978  ,  0.080085 , -0.55275  ,\n",
              "        0.28294  ,  0.032875 , -0.017581 ,  0.34842  ,  0.2692   ,\n",
              "        0.075113 , -0.37169  , -0.14129  , -0.40903  ,  0.41004  ,\n",
              "        0.22641  ,  0.28444  , -0.41261  , -0.063598 ,  0.19304  ,\n",
              "       -0.2316   , -0.40136  , -0.080943 , -0.27369  ,  0.16888  ,\n",
              "        0.393    , -0.031524 , -0.12764  , -0.42209  , -0.12337  ,\n",
              "       -0.39915  ,  0.14802  ,  0.36912  , -0.1445   , -0.31731  ,\n",
              "        0.10752  ,  0.091793 , -0.39809  ,  0.10421  , -0.13545  ,\n",
              "        0.45647  , -0.18203  , -0.73375  ,  0.10939  , -0.76302  ,\n",
              "       -0.19488  ,  0.15533  ,  0.32838  , -0.44536  ,  0.025172 ,\n",
              "       -0.12986  ,  0.030183 ,  0.50884  ,  0.13892  , -0.18833  ,\n",
              "       -0.37357  ,  0.0123   , -0.23761  , -0.038132 ,  0.38095  ,\n",
              "       -0.29728  ,  0.20762  ,  0.2139   ,  0.49598  , -0.48997  ,\n",
              "       -0.020849 ,  0.22817  , -0.079734 ,  0.18408  ,  0.50913  ,\n",
              "        0.26787  ,  0.071683 , -0.80692  ,  0.42534  , -0.55762  ,\n",
              "        0.34816  ,  0.486    , -0.29662  , -0.075876 ,  0.16479  ,\n",
              "        0.054647 , -0.16726  ,  0.23518  , -0.25424  ,  0.53356  ,\n",
              "       -0.90001  ,  0.22516  , -0.60991  ,  0.45944  ,  0.46214  ,\n",
              "       -0.33214  , -0.24009  , -0.11272  ,  0.44394  , -0.029143 ,\n",
              "       -0.75259  ,  0.083036 , -0.89395  , -0.27397  ,  0.052415 ,\n",
              "        0.33427  , -0.35963  ,  0.21667  , -0.010146 ,  0.036747 ,\n",
              "       -0.0031613,  0.51443  ,  0.56147  ,  0.7439   ,  0.5391   ,\n",
              "       -1.0815   ,  0.05796  ,  0.05885  , -0.64155  ,  0.25907  ,\n",
              "        0.75592  , -0.54389  ,  0.18612  ,  0.48994  , -0.41685  ,\n",
              "        0.13649  , -0.056544 , -0.097015 , -0.59311  , -0.47563  ,\n",
              "       -0.71797  ,  0.18686  ,  0.065219 , -0.13749  ,  0.22382  ,\n",
              "       -0.19464  ,  0.44058  ,  0.16716  ,  0.25417  ,  0.60995  ,\n",
              "       -0.83574  , -0.47141  ,  0.29427  , -0.17008  ,  0.31259  ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "dZOGAEt45yzJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Parsing Corpus of Conversations"
      ]
    },
    {
      "metadata": {
        "id": "o1zOfnwC55ji",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "So now we need some data for the bot. \n",
        "In particular, we need some conversations: the text of the turns along with information about which turn is in response to which. \n",
        "Some researchers at Cornell University have made available a very interesting corpus of conversations: The Cornell Movie Dialog Corpus, containing \"220,579 conversational exchanges between 10,292 pairs of movie characters.\" \n",
        "The data is stored in several plain text files, which can download by running the following cells:\n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "KPuS7jna517j",
        "colab_type": "code",
        "outputId": "b6a2a15f-449f-46ce-9b10-fe403c3849a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "cell_type": "code",
      "source": [
        "!curl -L -O http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 9684k  100 9684k    0     0  5915k      0  0:00:01  0:00:01 --:--:-- 5915k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kyvXDyr76Hm6",
        "colab_type": "code",
        "outputId": "9f1bcb6a-d084-465a-d56f-057116f87a66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip cornell_movie_dialogs_corpus.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cornell_movie_dialogs_corpus.zip\n",
            "   creating: cornell movie-dialogs corpus/\n",
            "  inflating: cornell movie-dialogs corpus/.DS_Store  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/cornell movie-dialogs corpus/\n",
            "  inflating: __MACOSX/cornell movie-dialogs corpus/._.DS_Store  \n",
            "  inflating: cornell movie-dialogs corpus/chameleons.pdf  \n",
            "  inflating: __MACOSX/cornell movie-dialogs corpus/._chameleons.pdf  \n",
            "  inflating: cornell movie-dialogs corpus/movie_characters_metadata.txt  \n",
            "  inflating: cornell movie-dialogs corpus/movie_conversations.txt  \n",
            "  inflating: cornell movie-dialogs corpus/movie_lines.txt  \n",
            "  inflating: cornell movie-dialogs corpus/movie_titles_metadata.txt  \n",
            "  inflating: cornell movie-dialogs corpus/raw_script_urls.txt  \n",
            "  inflating: cornell movie-dialogs corpus/README.txt  \n",
            "  inflating: __MACOSX/cornell movie-dialogs corpus/._README.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZxglkN2b6OQx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Will work with two files from this corpus:\n",
        "1. movie_lines.txt \n",
        "   Has the movie lines themselves, associated with a short unique identifier; \n",
        "2. movie_conversations.txt \n",
        "   Has lists of which lines occurred together in conversations, in the order in which they occurred. \n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "K9VkjJtV6KhP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The following parse the two files and create lookup dictionaries that associate unique IDs to lines (movie_lines) and each line to the line that follows it (responses).\n",
        "movie_lines = {}\n",
        "for line in open(\"./cornell movie-dialogs corpus/movie_lines.txt\",\n",
        "                 encoding=\"latin1\"):\n",
        "    line = line.strip()\n",
        "    parts = line.split(\" +++$+++ \")\n",
        "    if len(parts) == 5:\n",
        "        movie_lines[parts[0]] = parts[4]\n",
        "    else:\n",
        "        movie_lines[parts[0]] = \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h3EmGlyG6l7d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "responses = {}\n",
        "for line in open(\"./cornell movie-dialogs corpus/movie_conversations.txt\",\n",
        "                 encoding=\"latin1\"):\n",
        "    line = line.strip()\n",
        "    parts = line.split(\" +++$+++ \")\n",
        "    line_ids = json.loads(parts[3].replace(\"'\", '\"'))\n",
        "    for first, second in zip(line_ids[:-1], line_ids[1:]):\n",
        "        responses[first] = second"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R_UvsBG36pz6",
        "colab_type": "code",
        "outputId": "69ba7d06-8a9c-43bc-c71c-ba82c36d199f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "# Just to make sure everything works, the cell below prints out five random pairs of conversational turns from the corpus:\n",
        "\n",
        "import random\n",
        "for pair in random.sample(responses.items(), 5):\n",
        "    print(\"A:\", movie_lines[pair[0]])\n",
        "    print(\"B:\", movie_lines[pair[1]])\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A: They probably stopped off somewhere. Have her call me when she gets back. I've got Lyndsey here and I want to know what time to put her to bed.\n",
            "B: Okay. Later.\n",
            "\n",
            "A: From the grave?\n",
            "B: MyDick.\n",
            "\n",
            "A: My brother says he likes you, too.\n",
            "B: Really?\n",
            "\n",
            "A: Whistler!\n",
            "B: Are we bringing home strays now?\n",
            "\n",
            "A: Maybe.\n",
            "B: No, you weren't\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M3W7l9Eg6ydi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Making a Sentence Vector"
      ]
    },
    {
      "metadata": {
        "id": "mlw2Qc-a66um",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "To make the sentence vector for each line of dialog, will use spaCy. \n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "D5nHhbWG6wHC",
        "colab_type": "code",
        "outputId": "ccae44a9-9a7d-484d-f85b-12160baca06c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# The sentence_mean() function takes the spaCy object and uses it to tokenize the string that pass into the function (i.e., break it up into words)\n",
        "# It then uses numpy's mean() function to find the average of the vectors, producing a new vector. \n",
        "# The shape of the resulting vector (i.e., the number of dimensions) should be the same as the shape of the individual word vectors.\n",
        "import numpy as np\n",
        "def sentence_mean(nlp, s):\n",
        "    if s == \"\":\n",
        "        s = \" \"\n",
        "    doc = nlp(s, disable=['tagger', 'parser'])\n",
        "    return np.mean(np.array([w.vector for w in doc]), axis=0)\n",
        "sentence_mean(nlp, \"This... is a test.\").shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "xc0S8tM77f23",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Similarity Lookups"
      ]
    },
    {
      "metadata": {
        "id": "RSRTEmk77pJ3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "The kind of \"database\" wIll need to use for this is an approximate nearest neighbors lookup\n",
        "which allows you to store items along with the vector that represents them\n",
        "and then do fast searches to find items with similar vectors (even items that weren't in the original dataset).\n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "GBlqWM6-7XZp",
        "colab_type": "code",
        "outputId": "db62054b-1568-4a7c-e00a-b40bf627951d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install simpleneighbors"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting simpleneighbors\n",
            "  Downloading https://files.pythonhosted.org/packages/a2/8e/b8ca38e4305bdf5c4cac5d9bf4b65022a2d3641a978b28ce92f9e4063c7b/simpleneighbors-0.0.1-py2.py3-none-any.whl\n",
            "Collecting annoy (from simpleneighbors)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/bf/8e3f7051d694afc086184d223e892d0fc18aca1e4147042d0521a6adedb5/annoy-1.15.1.tar.gz (643kB)\n",
            "\u001b[K    100% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 645kB 24.8MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: annoy\n",
            "  Building wheel for annoy (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/77/cb/7a/6f3ed44099e394e0cb0b6b41213b61fe6595b726530744f2ce\n",
            "Successfully built annoy\n",
            "Installing collected packages: annoy, simpleneighbors\n",
            "Successfully installed annoy-1.15.1 simpleneighbors-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9ld1gDVT7zAB",
        "colab_type": "code",
        "outputId": "d272fef8-1b78-4599-ab33-594915090b48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "cell_type": "code",
      "source": [
        "from simpleneighbors import SimpleNeighbors\n",
        "\n",
        "# makes a new Simple Neighbors object called nns and initializes it with 300 dimensions (the shape of the word vectors in spaCy, and also the shape of our summary vectors)\n",
        "nns = SimpleNeighbors(300)\n",
        "\n",
        "# it then samples ten thousand random conversational turns from the Cornell corpus\n",
        "# finds sentence vectors for each of them and adds them to the database\n",
        "for i, line_id in enumerate(random.sample(list(responses.keys()), 10000)):\n",
        "    # show progress\n",
        "    if i % 1000 == 0: print(i, line_id, movie_lines[line_id])\n",
        "    line_text = movie_lines[line_id]\n",
        "    summary_vector = sentence_mean(nlp, line_text)\n",
        "# The np.any() line just checks to make sure that we don't add any vectors that are all zeroes by accident\n",
        "# this can mess up the nearest-neighbor search\n",
        "    if np.any(summary_vector):\n",
        "        nns.add_one(line_id, summary_vector)\n",
        "nns.build()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 L574934 What's so fucking funny?\n",
            "1000 L283957 Five hundred dollars.\n",
            "2000 L219544 My associates did a biopsy on this man recently.  He's supposed to have a melanoma, or a carcinoma, some kind of noma. Hmmm. I can't seem to find any record of it.\n",
            "3000 L113363 This is very awkward.\n",
            "4000 L28440 Then what would be enough?  If we were married?\n",
            "5000 L424172 Where? Where is she?\n",
            "6000 L147521 You rob an associate of mine... a friend and--\n",
            "7000 L23385 Close enough to walk to!\n",
            "8000 L326265 Bull shit .. I'm in my prime ..\n",
            "9000 L68383 Nixon lives in Saddle River, New York.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZLknpdwy8t47",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        " (You can change this string to whatever you want.) It then uses the Simple Neighbors object to find the turn in the database with the most similar vector, and then uses the responses lookup to find the response to that turn. That response will be our bot's output.\n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "G3WNFqqS8tK7",
        "colab_type": "code",
        "outputId": "1fbc54d8-a9e2-4b19-9458-331d42816945",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "cell_type": "code",
      "source": [
        "# this code finds the turn most similar to the string in the variable sentence\n",
        "# it then uses the Simple Neighbors object to find the turn in the database with the most similar vector\n",
        "# and then uses the Responses Lookup to find the response to that turn. \n",
        "sentence = \"I like making bots.\"\n",
        "picked = nns.nearest(sentence_mean(nlp, sentence), 5)[0]\n",
        "response_line_id = responses[picked]\n",
        "\n",
        "# that response will be our bot's output.\n",
        "print(\"Your line:\\n\\t\", sentence)\n",
        "print(\"Most similar turn:\\n\\t\", movie_lines[picked])\n",
        "print(\"Response to most similar turn:\\n\\t\", movie_lines[response_line_id])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your line:\n",
            "\t I like making bots.\n",
            "Most similar turn:\n",
            "\t I like it.\n",
            "Response to most similar turn:\n",
            "\t Blue ruin is cheap gin in case you were wondering.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "govOSRjg9Xmx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Make Online Chatbot"
      ]
    },
    {
      "metadata": {
        "id": "tnHSPNes9MUb",
        "colab_type": "code",
        "outputId": "c8a2bac1-3873-4334-e644-126a16d92500",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install https://github.com/aparrish/semanticsimilaritychatbot/archive/master.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/aparrish/semanticsimilaritychatbot/archive/master.zip\n",
            "  Downloading https://github.com/aparrish/semanticsimilaritychatbot/archive/master.zip\n",
            "\u001b[K     / 122kB 8.3MB/s\n",
            "Requirement already satisfied: simpleneighbors in /usr/local/lib/python3.6/dist-packages (from semanticsimilaritychatbot==0.0.1) (0.0.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from semanticsimilaritychatbot==0.0.1) (2.0.18)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from semanticsimilaritychatbot==0.0.1) (1.16.2)\n",
            "Requirement already satisfied: annoy in /usr/local/lib/python3.6/dist-packages (from simpleneighbors->semanticsimilaritychatbot==0.0.1) (1.15.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->semanticsimilaritychatbot==0.0.1) (2.0.2)\n",
            "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy->semanticsimilaritychatbot==0.0.1) (1.35)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->semanticsimilaritychatbot==0.0.1) (0.9.6)\n",
            "Requirement already satisfied: regex==2018.01.10 in /usr/local/lib/python3.6/dist-packages (from spacy->semanticsimilaritychatbot==0.0.1) (2018.1.10)\n",
            "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->semanticsimilaritychatbot==0.0.1) (0.2.9)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->semanticsimilaritychatbot==0.0.1) (1.0.2)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy->semanticsimilaritychatbot==0.0.1) (2.0.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy->semanticsimilaritychatbot==0.0.1) (2.18.4)\n",
            "Requirement already satisfied: thinc<6.13.0,>=6.12.1 in /usr/local/lib/python3.6/dist-packages (from spacy->semanticsimilaritychatbot==0.0.1) (6.12.1)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->semanticsimilaritychatbot==0.0.1) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->semanticsimilaritychatbot==0.0.1) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->semanticsimilaritychatbot==0.0.1) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy->semanticsimilaritychatbot==0.0.1) (2019.3.9)\n",
            "Requirement already satisfied: msgpack<0.6.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy->semanticsimilaritychatbot==0.0.1) (0.5.6)\n",
            "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy->semanticsimilaritychatbot==0.0.1) (1.10.11)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy->semanticsimilaritychatbot==0.0.1) (4.28.1)\n",
            "Requirement already satisfied: six<2.0.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy->semanticsimilaritychatbot==0.0.1) (1.11.0)\n",
            "Requirement already satisfied: msgpack-numpy<0.4.4 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy->semanticsimilaritychatbot==0.0.1) (0.4.3.2)\n",
            "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy->semanticsimilaritychatbot==0.0.1) (0.9.0.1)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy->semanticsimilaritychatbot==0.0.1) (0.9.0)\n",
            "Building wheels for collected packages: semanticsimilaritychatbot\n",
            "  Building wheel for semanticsimilaritychatbot (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-bzl5hifr/wheels/f7/af/8e/8a8fbef31bfbfc3b935425efa03db03825795d85f4e23f8255\n",
            "Successfully built semanticsimilaritychatbot\n",
            "Installing collected packages: semanticsimilaritychatbot\n",
            "Successfully installed semanticsimilaritychatbot-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2povt32F9c-8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a chatbot object, passing in the spaCy language object (nlp) and the number of dimensions\n",
        "from semanticsimilaritychatbot import SemanticSimilarityChatbot\n",
        "chatbot = SemanticSimilarityChatbot(nlp, 300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mJX_xg5M9mp0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# the .add_pair() method in the object takes two strings: a turn and the response to that turn\n",
        "# get these from the responses and movie_lines lookups\n",
        "# again sampling ten thousand pairs at random.\n",
        "sample_n = 10000\n",
        "\n",
        "for first_id, second_id in random.sample(list(responses.items()), sample_n):\n",
        "    chatbot.add_pair(movie_lines[first_id], movie_lines[second_id])\n",
        "chatbot.build()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qnV4FInh915d",
        "colab_type": "code",
        "outputId": "d7e7f49b-7200-4c76-c4cf-e03b959a538e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# the .response_for() method returns a plausible response from the database, based on semantic similarity\n",
        "print(chatbot.response_for(\"Hello computer!\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Han, don't. It'll be all right.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T9Z20J1h-LSZ",
        "colab_type": "code",
        "outputId": "91eecaa7-e221-4216-d654-21eab9c32943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "cell_type": "code",
      "source": [
        "# To add variety, the .response_for() method actually selects randomly among several similar turns.\n",
        "\n",
        "my_turn = \"The weather's nice today, don't you think?\"\n",
        "for i in range(5, 51, 5):\n",
        "    print(\"picking from\", i, \"possible responses:\")\n",
        "    print(chatbot.response_for(my_turn, i))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "picking from 5 possible responses:\n",
            "Of course. I would like to look.\n",
            "\n",
            "picking from 10 possible responses:\n",
            "You're mad, that's your trouble, you're mad.\n",
            "\n",
            "picking from 15 possible responses:\n",
            "I don't have to do any such thing. I'm eating my lunch, okay?\n",
            "\n",
            "picking from 20 possible responses:\n",
            "Everybody does?\n",
            "\n",
            "picking from 25 possible responses:\n",
            "Yeah, Dad.  I'm happy right now.\n",
            "\n",
            "picking from 30 possible responses:\n",
            "I don't have to do any such thing. I'm eating my lunch, okay?\n",
            "\n",
            "picking from 35 possible responses:\n",
            "Who wants true? Who wants moving?\n",
            "\n",
            "picking from 40 possible responses:\n",
            "Don't bother.\n",
            "\n",
            "picking from 45 possible responses:\n",
            "Who wants true? Who wants moving?\n",
            "\n",
            "picking from 50 possible responses:\n",
            "Mack, I'm just trying to keep up with now.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G2zy9g9b-aXl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# the Semantic Similarity Chatbot object has a .save() method that saves the pre-built database to disk, using a filename prefix you supply\n",
        "# It saves three different files: <prefix>.annoy, <prefix>-data.pkl, and <prefix>-chatbot.pkl\n",
        "chatbot.save(\"movielines-10k-sample\")\n",
        "\n",
        "'''able to use a previously-saved database using the .load() class method\n",
        "   this means you don't have to build the database again, can just load it and start calling .response_for().)\n",
        "'''\n",
        "chatbot = SemanticSimilarityChatbot.load(\"movielines-10k-sample\", nlp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aa5ToV9g-1HU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# download all of the files from the pre-built bot to your computer so we can use them later\n",
        "from google.colab import files\n",
        "files.download('movielines-10k-sample.annoy')\n",
        "files.download('movielines-10k-sample-data.pkl')\n",
        "files.download('movielines-10k-sample-chatbot.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ccFFKD5-_CBt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Making it Interactive"
      ]
    },
    {
      "metadata": {
        "id": "JQI9QFAk_Jgx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a little interactive interface for chatting with the bot that we just built\n",
        "\n",
        "chatbot_html = \"\"\"\n",
        "<style type=\"text/css\">#log p { margin: 5px; font-family: sans-serif; }</style>\n",
        "<div id=\"log\"\n",
        "     style=\"box-sizing: border-box;\n",
        "            width: 600px;\n",
        "            height: 32em;\n",
        "            border: 1px grey solid;\n",
        "            padding: 2px;\n",
        "            overflow: scroll;\">\n",
        "</div>\n",
        "<input type=\"text\" id=\"typehere\" placeholder=\"type here!\"\n",
        "       style=\"box-sizing: border-box;\n",
        "              width: 600px;\n",
        "              margin-top: 5px;\">\n",
        "<script>\n",
        "function paraWithText(t) {\n",
        "    let tn = document.createTextNode(t);\n",
        "    let ptag = document.createElement('p');\n",
        "    ptag.appendChild(tn);\n",
        "    return ptag;\n",
        "}\n",
        "document.querySelector('#typehere').onchange = async function() {\n",
        "    let inputField = document.querySelector('#typehere');\n",
        "    let val = inputField.value;\n",
        "    inputField.value = \"\";\n",
        "    let resp = await getResp(val);\n",
        "    let objDiv = document.getElementById(\"log\");\n",
        "    objDiv.appendChild(paraWithText('ðŸ˜€: ' + val));\n",
        "    objDiv.appendChild(paraWithText('ðŸ¤–: ' + resp));\n",
        "    objDiv.scrollTop = objDiv.scrollHeight;\n",
        "};\n",
        "async function colabGetResp(val) {\n",
        "    let resp = await google.colab.kernel.invokeFunction(\n",
        "        'notebook.get_response', [val], {});\n",
        "    return resp.data['application/json']['result'];\n",
        "}\n",
        "async function webGetResp(val) {\n",
        "    let resp = await fetch(\"/response.json?sentence=\" + \n",
        "        encodeURIComponent(val));\n",
        "    let data = await resp.json();\n",
        "    return data['result'];\n",
        "}\n",
        "</script>\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OMCrwl-w_aXZ",
        "colab_type": "code",
        "outputId": "d8575861-d210-4899-a37a-b494cf4c3d78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.HTML(chatbot_html + \\\n",
        "                             \"<script>let getResp = colabGetResp;</script>\"))\n",
        "\n",
        "def get_response(val):\n",
        "    resp = chatbot.response_for(val)\n",
        "    return IPython.display.JSON({'result': resp})\n",
        "\n",
        "output.register_callback('notebook.get_response', get_response)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<style type=\"text/css\">#log p { margin: 5px; font-family: sans-serif; }</style>\n",
              "<div id=\"log\"\n",
              "     style=\"box-sizing: border-box;\n",
              "            width: 600px;\n",
              "            height: 32em;\n",
              "            border: 1px grey solid;\n",
              "            padding: 2px;\n",
              "            overflow: scroll;\">\n",
              "</div>\n",
              "<input type=\"text\" id=\"typehere\" placeholder=\"type here!\"\n",
              "       style=\"box-sizing: border-box;\n",
              "              width: 600px;\n",
              "              margin-top: 5px;\">\n",
              "<script>\n",
              "function paraWithText(t) {\n",
              "    let tn = document.createTextNode(t);\n",
              "    let ptag = document.createElement('p');\n",
              "    ptag.appendChild(tn);\n",
              "    return ptag;\n",
              "}\n",
              "document.querySelector('#typehere').onchange = async function() {\n",
              "    let inputField = document.querySelector('#typehere');\n",
              "    let val = inputField.value;\n",
              "    inputField.value = \"\";\n",
              "    let resp = await getResp(val);\n",
              "    let objDiv = document.getElementById(\"log\");\n",
              "    objDiv.appendChild(paraWithText('ðŸ˜€: ' + val));\n",
              "    objDiv.appendChild(paraWithText('ðŸ¤–: ' + resp));\n",
              "    objDiv.scrollTop = objDiv.scrollHeight;\n",
              "};\n",
              "async function colabGetResp(val) {\n",
              "    let resp = await google.colab.kernel.invokeFunction(\n",
              "        'notebook.get_response', [val], {});\n",
              "    return resp.data['application/json']['result'];\n",
              "}\n",
              "async function webGetResp(val) {\n",
              "    let resp = await fetch(\"/response.json?sentence=\" + \n",
              "        encodeURIComponent(val));\n",
              "    let data = await resp.json();\n",
              "    return data['result'];\n",
              "}\n",
              "</script>\n",
              "<script>let getResp = colabGetResp;</script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}