{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 2.3 - Alexnet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rainniee/Neural-Networks-AI/blob/master/Assignment_2_3_Alexnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "jKHQdXPxte94",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load the tiny-imagenet-200"
      ]
    },
    {
      "metadata": {
        "id": "k5HECTT_swDE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51d6a098-a1d8-4e7c-af70-db4581471491"
      },
      "cell_type": "code",
      "source": [
        "import os, zipfile, io, requests\n",
        "URL = 'http://cs231n.stanford.edu/tiny-imagenet-200.zip'\n",
        "def download_images(url):\n",
        "    r = requests.get(url, stream=True)\n",
        "    print ('Downloading ' + url )\n",
        "    zip_ref = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "    zip_ref.extractall('./')\n",
        "    zip_ref.close()\n",
        "download_images(URL)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://cs231n.stanford.edu/tiny-imagenet-200.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Sa4cH_8Qto3i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Split the training and validation dataset"
      ]
    },
    {
      "metadata": {
        "id": "mgTDfpSutn4u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3377
        },
        "outputId": "f67da04c-d4d5-4f1a-ebdd-01719c022adf"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import six.moves.cPickle as pickle\n",
        "\n",
        "data = {}\n",
        "data['train'] = {}\n",
        "data['val'] = {}\n",
        "data['train']['image'] = []\n",
        "data['train']['label'] = []\n",
        "data['val']['image'] = []\n",
        "data['val']['label'] = []\n",
        "\n",
        "size = (32, 32)\n",
        "\n",
        "N = 400 \n",
        "## 80% as training dataset and 20% as validation dataset in each 500 images\n",
        "\n",
        "# First load wnids\n",
        "wnids = list(map(lambda x: x.strip(), open('tiny-imagenet-200/wnids.txt').readlines()))\n",
        "\n",
        "# Split the training and validation dataset\n",
        "for i in range(len(wnids)):\n",
        "    wnid = wnids[i]\n",
        "    print (\"{}: {} / {}\".format(wnid, i + 1, len(wnids)))\n",
        "    \n",
        "    for j in range(500):\n",
        "        path = \"tiny-imagenet-200/train/{0}/images/{0}_{1}.JPEG\".format(wnid, j)\n",
        "        image = (Image.open(path).convert('RGB'))\n",
        "        image = image.resize(size, Image.ANTIALIAS)\n",
        "        image = np.array(image)\n",
        "        if j < N:\n",
        "            data['train']['image'].append(image)\n",
        "            data['train']['label'].append(i)\n",
        "        else:\n",
        "            data['val']['image'].append(image)\n",
        "            data['val']['label'].append(i)\n",
        "\n",
        "# Dump train.pkl\n",
        "pickle.dump(data, open('train.pkl', 'wb', -1))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n02124075: 1 / 200\n",
            "n04067472: 2 / 200\n",
            "n04540053: 3 / 200\n",
            "n04099969: 4 / 200\n",
            "n07749582: 5 / 200\n",
            "n01641577: 6 / 200\n",
            "n02802426: 7 / 200\n",
            "n09246464: 8 / 200\n",
            "n07920052: 9 / 200\n",
            "n03970156: 10 / 200\n",
            "n03891332: 11 / 200\n",
            "n02106662: 12 / 200\n",
            "n03201208: 13 / 200\n",
            "n02279972: 14 / 200\n",
            "n02132136: 15 / 200\n",
            "n04146614: 16 / 200\n",
            "n07873807: 17 / 200\n",
            "n02364673: 18 / 200\n",
            "n04507155: 19 / 200\n",
            "n03854065: 20 / 200\n",
            "n03838899: 21 / 200\n",
            "n03733131: 22 / 200\n",
            "n01443537: 23 / 200\n",
            "n07875152: 24 / 200\n",
            "n03544143: 25 / 200\n",
            "n09428293: 26 / 200\n",
            "n03085013: 27 / 200\n",
            "n02437312: 28 / 200\n",
            "n07614500: 29 / 200\n",
            "n03804744: 30 / 200\n",
            "n04265275: 31 / 200\n",
            "n02963159: 32 / 200\n",
            "n02486410: 33 / 200\n",
            "n01944390: 34 / 200\n",
            "n09256479: 35 / 200\n",
            "n02058221: 36 / 200\n",
            "n04275548: 37 / 200\n",
            "n02321529: 38 / 200\n",
            "n02769748: 39 / 200\n",
            "n02099712: 40 / 200\n",
            "n07695742: 41 / 200\n",
            "n02056570: 42 / 200\n",
            "n02281406: 43 / 200\n",
            "n01774750: 44 / 200\n",
            "n02509815: 45 / 200\n",
            "n03983396: 46 / 200\n",
            "n07753592: 47 / 200\n",
            "n04254777: 48 / 200\n",
            "n02233338: 49 / 200\n",
            "n04008634: 50 / 200\n",
            "n02823428: 51 / 200\n",
            "n02236044: 52 / 200\n",
            "n03393912: 53 / 200\n",
            "n07583066: 54 / 200\n",
            "n04074963: 55 / 200\n",
            "n01629819: 56 / 200\n",
            "n09332890: 57 / 200\n",
            "n02481823: 58 / 200\n",
            "n03902125: 59 / 200\n",
            "n03404251: 60 / 200\n",
            "n09193705: 61 / 200\n",
            "n03637318: 62 / 200\n",
            "n04456115: 63 / 200\n",
            "n02666196: 64 / 200\n",
            "n03796401: 65 / 200\n",
            "n02795169: 66 / 200\n",
            "n02123045: 67 / 200\n",
            "n01855672: 68 / 200\n",
            "n01882714: 69 / 200\n",
            "n02917067: 70 / 200\n",
            "n02988304: 71 / 200\n",
            "n04398044: 72 / 200\n",
            "n02843684: 73 / 200\n",
            "n02423022: 74 / 200\n",
            "n02669723: 75 / 200\n",
            "n04465501: 76 / 200\n",
            "n02165456: 77 / 200\n",
            "n03770439: 78 / 200\n",
            "n02099601: 79 / 200\n",
            "n04486054: 80 / 200\n",
            "n02950826: 81 / 200\n",
            "n03814639: 82 / 200\n",
            "n04259630: 83 / 200\n",
            "n03424325: 84 / 200\n",
            "n02948072: 85 / 200\n",
            "n03179701: 86 / 200\n",
            "n03400231: 87 / 200\n",
            "n02206856: 88 / 200\n",
            "n03160309: 89 / 200\n",
            "n01984695: 90 / 200\n",
            "n03977966: 91 / 200\n",
            "n03584254: 92 / 200\n",
            "n04023962: 93 / 200\n",
            "n02814860: 94 / 200\n",
            "n01910747: 95 / 200\n",
            "n04596742: 96 / 200\n",
            "n03992509: 97 / 200\n",
            "n04133789: 98 / 200\n",
            "n03937543: 99 / 200\n",
            "n02927161: 100 / 200\n",
            "n01945685: 101 / 200\n",
            "n02395406: 102 / 200\n",
            "n02125311: 103 / 200\n",
            "n03126707: 104 / 200\n",
            "n04532106: 105 / 200\n",
            "n02268443: 106 / 200\n",
            "n02977058: 107 / 200\n",
            "n07734744: 108 / 200\n",
            "n03599486: 109 / 200\n",
            "n04562935: 110 / 200\n",
            "n03014705: 111 / 200\n",
            "n04251144: 112 / 200\n",
            "n04356056: 113 / 200\n",
            "n02190166: 114 / 200\n",
            "n03670208: 115 / 200\n",
            "n02002724: 116 / 200\n",
            "n02074367: 117 / 200\n",
            "n04285008: 118 / 200\n",
            "n04560804: 119 / 200\n",
            "n04366367: 120 / 200\n",
            "n02403003: 121 / 200\n",
            "n07615774: 122 / 200\n",
            "n04501370: 123 / 200\n",
            "n03026506: 124 / 200\n",
            "n02906734: 125 / 200\n",
            "n01770393: 126 / 200\n",
            "n04597913: 127 / 200\n",
            "n03930313: 128 / 200\n",
            "n04118538: 129 / 200\n",
            "n04179913: 130 / 200\n",
            "n04311004: 131 / 200\n",
            "n02123394: 132 / 200\n",
            "n04070727: 133 / 200\n",
            "n02793495: 134 / 200\n",
            "n02730930: 135 / 200\n",
            "n02094433: 136 / 200\n",
            "n04371430: 137 / 200\n",
            "n04328186: 138 / 200\n",
            "n03649909: 139 / 200\n",
            "n04417672: 140 / 200\n",
            "n03388043: 141 / 200\n",
            "n01774384: 142 / 200\n",
            "n02837789: 143 / 200\n",
            "n07579787: 144 / 200\n",
            "n04399382: 145 / 200\n",
            "n02791270: 146 / 200\n",
            "n03089624: 147 / 200\n",
            "n02814533: 148 / 200\n",
            "n04149813: 149 / 200\n",
            "n07747607: 150 / 200\n",
            "n03355925: 151 / 200\n",
            "n01983481: 152 / 200\n",
            "n04487081: 153 / 200\n",
            "n03250847: 154 / 200\n",
            "n03255030: 155 / 200\n",
            "n02892201: 156 / 200\n",
            "n02883205: 157 / 200\n",
            "n03100240: 158 / 200\n",
            "n02415577: 159 / 200\n",
            "n02480495: 160 / 200\n",
            "n01698640: 161 / 200\n",
            "n01784675: 162 / 200\n",
            "n04376876: 163 / 200\n",
            "n03444034: 164 / 200\n",
            "n01917289: 165 / 200\n",
            "n01950731: 166 / 200\n",
            "n03042490: 167 / 200\n",
            "n07711569: 168 / 200\n",
            "n04532670: 169 / 200\n",
            "n03763968: 170 / 200\n",
            "n07768694: 171 / 200\n",
            "n02999410: 172 / 200\n",
            "n03617480: 173 / 200\n",
            "n06596364: 174 / 200\n",
            "n01768244: 175 / 200\n",
            "n02410509: 176 / 200\n",
            "n03976657: 177 / 200\n",
            "n01742172: 178 / 200\n",
            "n03980874: 179 / 200\n",
            "n02808440: 180 / 200\n",
            "n02226429: 181 / 200\n",
            "n02231487: 182 / 200\n",
            "n02085620: 183 / 200\n",
            "n01644900: 184 / 200\n",
            "n02129165: 185 / 200\n",
            "n02699494: 186 / 200\n",
            "n03837869: 187 / 200\n",
            "n02815834: 188 / 200\n",
            "n07720875: 189 / 200\n",
            "n02788148: 190 / 200\n",
            "n02909870: 191 / 200\n",
            "n03706229: 192 / 200\n",
            "n07871810: 193 / 200\n",
            "n03447447: 194 / 200\n",
            "n02113799: 195 / 200\n",
            "n12267677: 196 / 200\n",
            "n03662601: 197 / 200\n",
            "n02841315: 198 / 200\n",
            "n07715103: 199 / 200\n",
            "n02504458: 200 / 200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i_DKbQJ8tsZx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "(x_train, y_train), (x_val, y_val) = (data['train']['image'],data['train']['label']),(data['val']['image'],data['val']['label'])\n",
        "\n",
        "num_classes=200\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "x_val = np.array(x_val)\n",
        "x_train =x_train/ 255\n",
        "x_val = x_val/255\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_val = keras.utils.to_categorical(y_val, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "omnC6js3MUSa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import register_converters as _register_converters\n",
        "from keras.preprocessing import image\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten,\\\n",
        "Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras import optimizers\n",
        "\n",
        "import argparse\n",
        "\n",
        "# Import necessary components to build alexnet\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "\n",
        "from time import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZCXY4BuHMlSx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1092
        },
        "outputId": "d71936d1-4fa4-4358-d6a7-49abf9d36075"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "np.random.seed(1000)\n",
        "\n",
        "from keras import backend as K\n",
        "K.set_image_dim_ordering('th')\n",
        "\n",
        "print('AlexNet Implementation Using Keras')\n",
        "  \n",
        "logs = \"logs/AlexNet/\"     \n",
        "model_name = 'AlexNet_TinyImagenet200.h5'\n",
        "\n",
        "\n",
        "#Instantiate an empty model\n",
        "model = Sequential()\n",
        "\n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=96, input_shape=x_train.shape[1:], kernel_size=(11,11), strides=(4,4), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "# Max Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='same', data_format = 'channels_first'))\n",
        "model.add(Activation('relu'))\n",
        "# Max Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "# 3rd Convolutional Layer\n",
        "model.add(ZeroPadding2D((1, 1)))\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same', data_format = 'channels_first'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# 4th Convolutional Layer\n",
        "model.add(ZeroPadding2D((1, 1)))\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same', data_format = 'channels_first'))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# 5th Convolutional Layer\n",
        "model.add(ZeroPadding2D((1, 1)))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same', data_format = 'channels_first'))\n",
        "model.add(Activation('relu'))\n",
        "# Max Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "# Passing it to a Fully Connected layer\n",
        "model.add(Flatten())\n",
        "# 1st Fully Connected Layer\n",
        "model.add(Dense(4096, input_shape=(32*32*3,)))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# 2nd Fully Connected Layer\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# 3rd Fully Connected Layer\n",
        "model.add(Dense(1000))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(200))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AlexNet Implementation Using Keras\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_26 (Conv2D)           (None, 96, 8, 1)          371808    \n",
            "_________________________________________________________________\n",
            "activation_27 (Activation)   (None, 96, 8, 1)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 96, 4, 1)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 256, 4, 1)         2973952   \n",
            "_________________________________________________________________\n",
            "activation_28 (Activation)   (None, 256, 4, 1)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 256, 2, 1)         0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_7 (ZeroPaddin (None, 256, 4, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 384, 4, 3)         885120    \n",
            "_________________________________________________________________\n",
            "activation_29 (Activation)   (None, 384, 4, 3)         0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_8 (ZeroPaddin (None, 384, 6, 5)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 384, 6, 5)         1327488   \n",
            "_________________________________________________________________\n",
            "activation_30 (Activation)   (None, 384, 6, 5)         0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_9 (ZeroPaddin (None, 384, 8, 7)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 256, 8, 7)         884992    \n",
            "_________________________________________________________________\n",
            "activation_31 (Activation)   (None, 256, 8, 7)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 256, 4, 4)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "activation_32 (Activation)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "activation_33 (Activation)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "activation_34 (Activation)   (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 200)               200200    \n",
            "_________________________________________________________________\n",
            "activation_35 (Activation)   (None, 200)               0         \n",
            "=================================================================\n",
            "Total params: 44,303,184\n",
            "Trainable params: 44,303,184\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X9Rk1Gx_Qq1B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        },
        "outputId": "a5c5d7ca-9f43-4f4c-a0b0-0eb35e159d14"
      },
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=[\"accuracy\"])\n",
        "\n",
        "batch_size = 512\n",
        "num_classes = 200\n",
        "num_epochs = 20\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=num_epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_val, y_val))\n",
        "\n",
        "# Score trained model.\n",
        "scores = model.evaluate(x_val, y_val, verbose=1)\n",
        "\n",
        "print('Validation loss:', scores[0])\n",
        "print('Validation accuracy:', scores[1])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 80000 samples, validate on 20000 samples\n",
            "Epoch 1/20\n",
            "80000/80000 [==============================] - 49s 619us/step - loss: 5.2991 - acc: 0.0041 - val_loss: 5.2983 - val_acc: 0.0050\n",
            "Epoch 2/20\n",
            "80000/80000 [==============================] - 40s 495us/step - loss: 5.2987 - acc: 0.0045 - val_loss: 5.2983 - val_acc: 0.0050\n",
            "Epoch 3/20\n",
            "80000/80000 [==============================] - 39s 490us/step - loss: 5.2986 - acc: 0.0041 - val_loss: 5.2983 - val_acc: 0.0050\n",
            "Epoch 4/20\n",
            "80000/80000 [==============================] - 39s 490us/step - loss: 5.2986 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050\n",
            "Epoch 5/20\n",
            "80000/80000 [==============================] - 39s 492us/step - loss: 5.2986 - acc: 0.0041 - val_loss: 5.2983 - val_acc: 0.0050\n",
            "Epoch 6/20\n",
            "80000/80000 [==============================] - 39s 492us/step - loss: 5.2986 - acc: 0.0046 - val_loss: 5.2983 - val_acc: 0.0050\n",
            "Epoch 7/20\n",
            "80000/80000 [==============================] - 39s 492us/step - loss: 5.2986 - acc: 0.0041 - val_loss: 5.2983 - val_acc: 0.0050\n",
            "Epoch 8/20\n",
            "80000/80000 [==============================] - 40s 498us/step - loss: 5.2986 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050\n",
            "Epoch 9/20\n",
            "80000/80000 [==============================] - 40s 497us/step - loss: 5.2986 - acc: 0.0040 - val_loss: 5.2983 - val_acc: 0.0050\n",
            "Epoch 10/20\n",
            "80000/80000 [==============================] - 41s 514us/step - loss: 5.2986 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050\n",
            "Epoch 11/20\n",
            "80000/80000 [==============================] - 40s 499us/step - loss: 5.2986 - acc: 0.0047 - val_loss: 5.2983 - val_acc: 0.0050\n",
            "Epoch 12/20\n",
            "80000/80000 [==============================] - 41s 514us/step - loss: 5.2986 - acc: 0.0044 - val_loss: 5.2983 - val_acc: 0.0050\n",
            "Epoch 13/20\n",
            "80000/80000 [==============================] - 40s 499us/step - loss: 5.2986 - acc: 0.0043 - val_loss: 5.2983 - val_acc: 0.0050\n",
            "Epoch 14/20\n",
            "80000/80000 [==============================] - 40s 501us/step - loss: 5.2986 - acc: 0.0045 - val_loss: 5.2983 - val_acc: 0.0050\n",
            "Epoch 15/20\n",
            "80000/80000 [==============================] - 62s 775us/step - loss: 5.2986 - acc: 0.0046 - val_loss: 5.2983 - val_acc: 0.0050\n",
            "Epoch 16/20\n",
            "80000/80000 [==============================] - 62s 770us/step - loss: 5.2986 - acc: 0.0041 - val_loss: 5.2983 - val_acc: 0.0050\n",
            "Epoch 17/20\n",
            "80000/80000 [==============================] - 61s 768us/step - loss: 5.2986 - acc: 0.0042 - val_loss: 5.2983 - val_acc: 0.0050\n",
            "Epoch 18/20\n",
            "80000/80000 [==============================] - 62s 769us/step - loss: 5.2986 - acc: 0.0042 - val_loss: 5.2983 - val_acc: 0.0050\n",
            "Epoch 19/20\n",
            "80000/80000 [==============================] - 61s 768us/step - loss: 5.2986 - acc: 0.0041 - val_loss: 5.2983 - val_acc: 0.0050\n",
            "Epoch 20/20\n",
            "80000/80000 [==============================] - 61s 766us/step - loss: 5.2986 - acc: 0.0045 - val_loss: 5.2983 - val_acc: 0.0050\n",
            "20000/20000 [==============================] - 11s 564us/step\n",
            "Validation loss: 5.2983208290100094\n",
            "Validation accuracy: 0.005\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}