{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experiment1_RNN & GloVe.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rainniee/Neural-Networks-AI/blob/master/Experiment1_RNN%20%26%20GloVe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "P0iADOgbRt9y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "43e0ca9f-aeb4-4c34-853b-a8063a166ed4"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import itertools\n",
        "import os\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.datasets import imdb\n",
        "from tensorflow import keras\n",
        "from keras.layers import Embedding, Flatten, Dense, SimpleRNN, LSTM, Activation, Dropout\n",
        "from keras.layers import LSTM, CuDNNLSTM\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import utils\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# This code was tested with TensorFlow v1.4\n",
        "print(\"You have TensorFlow version\", tf.__version__)\n",
        "\n",
        "from distutils.version import LooseVersion as LV\n",
        "from keras import __version__\n",
        "from keras import backend as K\n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You have TensorFlow version 1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z3K78PvDRwi8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a70ba144-7179-4e6e-ab8a-629a6e2d6817"
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cleanedfinancial_data.csv  FinanceSentiments.csv  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oRZvGa-tSZvB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b94bdc8b-23a7-49e7-ff13-9e087e3f351b"
      },
      "cell_type": "code",
      "source": [
        "financial_data = pd.read_csv('cleanedfinancial_data.csv')\n",
        "financial_data.drop(columns=\"Unnamed: 0\", inplace=True)\n",
        "\n",
        "financial_data.iloc[2,1]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Well, we need to bring the Shanghai factory online. I think that's the biggest driver for getting to 500K plus a year. Our car is just very expensive going into China. We've got import duties. We've got transport costs. We've got higher-cost labor here. And we've never been eligible for any of the EV tax credits. A lot of people sort of dependent on incentives. In fact, we are [indiscernible] EVs, we have the least access to incentives. It's pretty crazy because there's so many companies that - countries that have put price caps on the EV incentive, which affects Tesla. And in China, which is the biggest market for EVs, we've never had any subsidies or tax incentives for vehicles.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "mFX1MebcWgr2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12b0e704-2b3c-4560-fb1d-db0745bdc2fc"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "financial_data.shape[0]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1649"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "z6qFs7dRWg1f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "a9b15b3e-5723-41f7-b955-a933ee04408d"
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize as wt \n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "stemmer = PorterStemmer()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XKX25u4yWg33",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9828eaf4-d5f8-423c-e637-c44aae1c3870"
      },
      "cell_type": "code",
      "source": [
        "financial_data.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1649, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "-Jt1q6hvWg6e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = []\n",
        "\n",
        "financial_test = financial_data[financial_data['sentiment'] != 'neutral']\n",
        "\n",
        "for i in range(financial_test.shape[0]):\n",
        "    sms = financial_test.iloc[i, 1]\n",
        "\n",
        "    # remove non alphabatic characters\n",
        "    sms = re.sub('[^A-Za-z]', ' ', sms)\n",
        "\n",
        "    # make words lowercase, because Go and go will be considered as two words\n",
        "    sms = sms.lower()\n",
        "\n",
        "    # tokenising\n",
        "    tokenized_sms = wt(sms)\n",
        "\n",
        "    # remove stop words and stemming\n",
        " \n",
        "    sms_processed = []\n",
        "    for word in tokenized_sms:\n",
        "        if word not in set(stopwords.words('english')):\n",
        "            sms_processed.append(stemmer.stem(word))\n",
        "\n",
        "    sms_text = \" \".join(sms_processed)\n",
        "    data.append(sms_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WcbA7mShiV_a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "80d6ff34-f122-46dc-b153-84db2e4d03ba"
      },
      "cell_type": "code",
      "source": [
        "financial_test['sentiment'] = financial_test['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)\n",
        "\n",
        "X = tokenizer.texts_to_matrix(financial_test['text'].tolist(), mode='freq')\n",
        "y = np.asarray(financial_test['sentiment'])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Mc6SEWorfn0R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# split train and test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hPOs0P3pXRQS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "5bfdaab4-7c27-4808-f19a-73f687e557ed"
      },
      "cell_type": "code",
      "source": [
        "# number of most-frequent words to use\n",
        "nb_words = 10000\n",
        "# cut texts after this number of words\n",
        "maxlen = 2000\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('y_test shape:', y_test.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pad sequences (samples x time)\n",
            "x_train shape: (648, 2000)\n",
            "x_test shape: (163, 2000)\n",
            "y_train shape: (648,)\n",
            "y_test shape: (163,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w3hyw49dc7pV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "50e398ed-7c34-41ed-d82f-128e1f118929"
      },
      "cell_type": "code",
      "source": [
        "print(\"First review in the training set:\\n\", x_train[0], \"length:\", len(x_train[0]), \"class:\", y_train[0])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First review in the training set:\n",
            " [0 0 0 ... 0 0 0] length: 2000 class: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Gd2UFGGTS166",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "a1cfcf60-5580-462f-a774-af2aff773db5"
      },
      "cell_type": "code",
      "source": [
        "# model parameters:\n",
        "embedding_dims = 50\n",
        "lstm_units = 32\n",
        "\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(nb_words,\n",
        "                    embedding_dims,\n",
        "                    input_length=maxlen))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# model.add(LSTM(lstm_units))\n",
        "# running on a GPU:\n",
        "model.add(CuDNNLSTM(lstm_units))\n",
        "\n",
        "# To stack multiple RNN layers, all RNN layers except the last one need\n",
        "# to have \"return_sequences=True\".  An example of using two RNN layers:\n",
        "#model.add(LSTM(lstm_units, return_sequences=True))\n",
        "#model.add(LSTM(lstm_units))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 2000, 50)          500000    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2000, 50)          0         \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_1 (CuDNNLSTM)     (None, 32)                10752     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 510,785\n",
            "Trainable params: 510,785\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Tkbe0MB7S19M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "outputId": "441203e2-cdca-4851-ad1a-661df380d21c"
      },
      "cell_type": "code",
      "source": [
        "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"377pt\" viewBox=\"0.00 0.00 377.00 377.00\" width=\"377pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 373)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-373 373,-373 373,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140337656441208 -->\n<g class=\"node\" id=\"node1\">\n<title>140337656441208</title>\n<polygon fill=\"none\" points=\"11.5,-249.5 11.5,-295.5 357.5,-295.5 357.5,-249.5 11.5,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"97\" y=\"-268.8\">embedding_1: Embedding</text>\n<polyline fill=\"none\" points=\"182.5,-249.5 182.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.5\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"182.5,-272.5 240.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.5\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"240.5,-249.5 240.5,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"299\" y=\"-280.3\">(None, 2000)</text>\n<polyline fill=\"none\" points=\"240.5,-272.5 357.5,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"299\" y=\"-257.3\">(None, 2000, 50)</text>\n</g>\n<!-- 140335799878432 -->\n<g class=\"node\" id=\"node2\">\n<title>140335799878432</title>\n<polygon fill=\"none\" points=\"30,-166.5 30,-212.5 339,-212.5 339,-166.5 30,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"97\" y=\"-185.8\">dropout_1: Dropout</text>\n<polyline fill=\"none\" points=\"164,-166.5 164,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"164,-189.5 222,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"193\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"222,-166.5 222,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"280.5\" y=\"-197.3\">(None, 2000, 50)</text>\n<polyline fill=\"none\" points=\"222,-189.5 339,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"280.5\" y=\"-174.3\">(None, 2000, 50)</text>\n</g>\n<!-- 140337656441208&#45;&gt;140335799878432 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140337656441208-&gt;140335799878432</title>\n<path d=\"M184.5,-249.3799C184.5,-241.1745 184.5,-231.7679 184.5,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"188.0001,-222.784 184.5,-212.784 181.0001,-222.784 188.0001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140335799891224 -->\n<g class=\"node\" id=\"node3\">\n<title>140335799891224</title>\n<polygon fill=\"none\" points=\"0,-83.5 0,-129.5 369,-129.5 369,-83.5 0,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"97\" y=\"-102.8\">cu_dnnlstm_1: CuDNNLSTM</text>\n<polyline fill=\"none\" points=\"194,-83.5 194,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"223\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"194,-106.5 252,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"223\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"252,-83.5 252,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310.5\" y=\"-114.3\">(None, 2000, 50)</text>\n<polyline fill=\"none\" points=\"252,-106.5 369,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310.5\" y=\"-91.3\">(None, 32)</text>\n</g>\n<!-- 140335799878432&#45;&gt;140335799891224 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140335799878432-&gt;140335799891224</title>\n<path d=\"M184.5,-166.3799C184.5,-158.1745 184.5,-148.7679 184.5,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"188.0001,-139.784 184.5,-129.784 181.0001,-139.784 188.0001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140335799893072 -->\n<g class=\"node\" id=\"node4\">\n<title>140335799893072</title>\n<polygon fill=\"none\" points=\"62,-.5 62,-46.5 307,-46.5 307,-.5 62,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"115.5\" y=\"-19.8\">dense_1: Dense</text>\n<polyline fill=\"none\" points=\"169,-.5 169,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"169,-23.5 227,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"198\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"227,-.5 227,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267\" y=\"-31.3\">(None, 32)</text>\n<polyline fill=\"none\" points=\"227,-23.5 307,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267\" y=\"-8.3\">(None, 1)</text>\n</g>\n<!-- 140335799891224&#45;&gt;140335799893072 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140335799891224-&gt;140335799893072</title>\n<path d=\"M184.5,-83.3799C184.5,-75.1745 184.5,-65.7679 184.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"188.0001,-56.784 184.5,-46.784 181.0001,-56.784 188.0001,-56.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140335799706120 -->\n<g class=\"node\" id=\"node5\">\n<title>140335799706120</title>\n<polygon fill=\"none\" points=\"120,-332.5 120,-368.5 249,-368.5 249,-332.5 120,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184.5\" y=\"-346.8\">140335799706120</text>\n</g>\n<!-- 140335799706120&#45;&gt;140337656441208 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140335799706120-&gt;140337656441208</title>\n<path d=\"M184.5,-332.4092C184.5,-324.4308 184.5,-314.795 184.5,-305.606\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"188.0001,-305.5333 184.5,-295.5333 181.0001,-305.5334 188.0001,-305.5333\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "p2-VaEjse7Nz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "f32ce98f-68af-49b5-8d5f-0e941d096f3f"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "epochs = 10\n",
        "validation_split = 0.2\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=128,\n",
        "          epochs=epochs, \n",
        "          validation_split=validation_split)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 518 samples, validate on 130 samples\n",
            "Epoch 1/10\n",
            "518/518 [==============================] - 6s 11ms/step - loss: 0.6492 - acc: 0.7278 - val_loss: 0.6099 - val_acc: 0.7769\n",
            "Epoch 2/10\n",
            "518/518 [==============================] - 1s 2ms/step - loss: 0.5522 - acc: 0.8185 - val_loss: 0.5324 - val_acc: 0.7769\n",
            "Epoch 3/10\n",
            "518/518 [==============================] - 1s 2ms/step - loss: 0.4760 - acc: 0.8185 - val_loss: 0.5363 - val_acc: 0.7769\n",
            "Epoch 4/10\n",
            "518/518 [==============================] - 1s 2ms/step - loss: 0.4746 - acc: 0.8185 - val_loss: 0.5655 - val_acc: 0.7769\n",
            "Epoch 5/10\n",
            "518/518 [==============================] - 1s 2ms/step - loss: 0.4780 - acc: 0.8185 - val_loss: 0.5308 - val_acc: 0.7769\n",
            "Epoch 6/10\n",
            "518/518 [==============================] - 1s 2ms/step - loss: 0.4780 - acc: 0.8185 - val_loss: 0.5310 - val_acc: 0.7769\n",
            "Epoch 7/10\n",
            "518/518 [==============================] - 1s 2ms/step - loss: 0.4764 - acc: 0.8185 - val_loss: 0.5380 - val_acc: 0.7769\n",
            "Epoch 8/10\n",
            "518/518 [==============================] - 1s 2ms/step - loss: 0.4748 - acc: 0.8185 - val_loss: 0.5398 - val_acc: 0.7769\n",
            "Epoch 9/10\n",
            "518/518 [==============================] - 1s 2ms/step - loss: 0.4741 - acc: 0.8185 - val_loss: 0.5550 - val_acc: 0.7769\n",
            "Epoch 10/10\n",
            "518/518 [==============================] - 1s 2ms/step - loss: 0.4765 - acc: 0.8185 - val_loss: 0.5311 - val_acc: 0.7769\n",
            "CPU times: user 9.89 s, sys: 2.27 s, total: 12.2 s\n",
            "Wall time: 15.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LfGIBoaAe7HD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "79974a71-fc19-42a7-c29a-79d5c46b26f5"
      },
      "cell_type": "code",
      "source": [
        "score, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (acc*100))\n",
        "print(\"Test score: %.2f%%\" % (score*100))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 79.14%\n",
            "Test score: 51.39%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kdisvN8GkF2r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "outputId": "f3bd4eec-335a-4f93-807e-435e22eb96ef"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "y_pred = model.predict_classes(np.array(x_test))\n",
        "\n",
        "from sklearn import metrics\n",
        "print(metrics.accuracy_score(y_test, y_pred))\n",
        "target_names = ['pos', 'neg']\n",
        "cnf_matrix_test = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "print(cnf_matrix_test)\n",
        "\n",
        "df_cm = pd.DataFrame(cnf_matrix_test, range(2), range(2))\n",
        "\n",
        "sns.set(font_scale=1.4)\n",
        "sns.heatmap(df_cm, annot=True, fmt='d')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7914110429447853\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         pos       0.00      0.00      0.00        34\n",
            "         neg       0.79      1.00      0.88       129\n",
            "\n",
            "   micro avg       0.79      0.79      0.79       163\n",
            "   macro avg       0.40      0.50      0.44       163\n",
            "weighted avg       0.63      0.79      0.70       163\n",
            "\n",
            "[[  0  34]\n",
            " [  0 129]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa2698bfbe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAFOCAYAAAALoy1VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "2AhYq9BkcA6f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6bda7fb6-cfe8-4ef4-bd37-5a77cff56f34"
      },
      "cell_type": "code",
      "source": [
        "TP = cnf_matrix_test[1, 1]\n",
        "TN = cnf_matrix_test[0, 0]\n",
        "FP = cnf_matrix_test[0, 1]\n",
        "FN = cnf_matrix_test[1, 0]\n",
        "\n",
        "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
        "print(classification_error)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2085889570552147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O7UerrKRlSjQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SGs7UdfDlSoY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "615cac88-3d21-43b9-b02d-a0df92282fab"
      },
      "cell_type": "code",
      "source": [
        "if not os.path.exists('glove.6B.zip'):\n",
        "    ! wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "if not os.path.exists('glove.6B.50d.txt'):\n",
        "    ! unzip glove.6B.zip"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-21 09:29:19--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-03-21 09:29:19--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.50MB/s    in 6m 52s  \n",
            "\n",
            "2019-03-21 09:36:12 (1.99 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dm_Jg4PLlSuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "9be625a2-c1fd-4f74-f0f6-6ef21b1f11bb"
      },
      "cell_type": "code",
      "source": [
        "vocab_size = 5000\n",
        "embedding_size = 50\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "def load_glove_embeddings(path):\n",
        "    embeddings = {}\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.strip().split()\n",
        "            w = values[0]\n",
        "            vectors = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings[w] = vectors\n",
        "\n",
        "    embedding_matrix = np.random.uniform(-1, 1, size=(vocab_size, embedding_size))\n",
        "    num_loaded = 0\n",
        "    for w, i in word_index.items():\n",
        "        v = embeddings.get(w)\n",
        "        if v is not None and i < vocab_size:\n",
        "            embedding_matrix[i] = v\n",
        "            num_loaded += 1\n",
        "    print('Successfully loaded pretrained embeddings for '\n",
        "          f'{num_loaded}/{vocab_size} words.')\n",
        "    embedding_matrix = embedding_matrix.astype(np.float32)\n",
        "    return embedding_matrix\n",
        "\n",
        "embedding_matrix = load_glove_embeddings('glove.6B.50d.txt')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "Successfully loaded pretrained embeddings for 4920/5000 words.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I05QHCT4lStN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def my_initializer(shape=None, dtype=tf.float32, partition_info=None):\n",
        "    assert dtype is tf.float32\n",
        "    return embedding_matrix\n",
        "\n",
        "params = {'embedding_initializer': my_initializer}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fsmdXlrwqTck",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentence_size = 200\n",
        "x_len_train = np.array([min(len(x), sentence_size) for x in x_train])\n",
        "x_len_test = np.array([min(len(x), sentence_size) for x in x_test])\n",
        "\n",
        "def parser(x, length, y):\n",
        "    features = {\"x\": x, \"len\": length}\n",
        "    return features, y\n",
        "\n",
        "def train_input_fn():\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x_train, x_len_train, y_train))\n",
        "    dataset = dataset.shuffle(buffer_size=len(x_train))\n",
        "    dataset = dataset.batch(100)\n",
        "    dataset = dataset.map(parser)\n",
        "    dataset = dataset.repeat()\n",
        "    iterator = dataset.make_one_shot_iterator()\n",
        "    return iterator.get_next()\n",
        "\n",
        "def eval_input_fn():\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x_test, x_len_test, y_test))\n",
        "    dataset = dataset.batch(100)\n",
        "    dataset = dataset.map(parser)\n",
        "    iterator = dataset.make_one_shot_iterator()\n",
        "    return iterator.get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o5p4udViqaoE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "72d8dac0-93dc-4a1c-c96a-ac02a6dd552a"
      },
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "model_dir = tempfile.mkdtemp()\n",
        "\n",
        "column = tf.feature_column.categorical_column_with_identity('x_train', vocab_size)\n",
        "classifier = tf.estimator.LinearClassifier(feature_columns=[column], model_dir=os.path.join(model_dir, 'bow_sparse'))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpfk_swc9j/bow_sparse', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa24c309e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YQt0ushIqauy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_classifiers = {}\n",
        "def train_and_evaluate(classifier):\n",
        "    # Save a reference to the classifier to run predictions later\n",
        "    all_classifiers[classifier.model_dir] = classifier\n",
        "    classifier.train(input_fn=train_input_fn, steps=25000)\n",
        "    eval_results = classifier.evaluate(input_fn=eval_input_fn)\n",
        "    predictions = np.array([p['logistic'][0] for p in classifier.predict(input_fn=eval_input_fn)])\n",
        "        \n",
        "    # Reset the graph to be able to reuse name scopes\n",
        "    tf.reset_default_graph() \n",
        "    # Add a PR summary in addition to the summaries that the classifier writes\n",
        "    pr = summary_lib.pr_curve('precision_recall', predictions=predictions, labels=y_test.astype(bool), num_thresholds=21)\n",
        "    with tf.Session() as sess:\n",
        "        writer = tf.summary.FileWriter(os.path.join(classifier.model_dir, 'eval'), sess.graph)\n",
        "        writer.add_summary(sess.run(pr), global_step=0)\n",
        "        writer.close()\n",
        "#     # Un-comment code to download experiment data from Colaboratory\n",
        "#     from google.colab import files\n",
        "#     model_name = os.path.basename(os.path.normpath(classifier.model_dir))\n",
        "#     ! zip -r {model_name + '.zip'} {classifier.model_dir}\n",
        "#     files.download(model_name + '.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0f5nwAIAsSoO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "1f3dbab7-23a4-439e-d9e8-5dcfb77988ab"
      },
      "cell_type": "code",
      "source": [
        "head = tf.contrib.estimator.binary_classification_head()\n",
        "\n",
        "def cnn_model_fn(features, labels, mode, params):    \n",
        "    input_layer = tf.contrib.layers.embed_sequence(\n",
        "        features['x'], vocab_size, embedding_size,\n",
        "        initializer=params['embedding_initializer'])\n",
        "    \n",
        "    training = mode == tf.estimator.ModeKeys.TRAIN\n",
        "    dropout_emb = tf.layers.dropout(inputs=input_layer, \n",
        "                                    rate=0.2, \n",
        "                                    training=training)\n",
        "\n",
        "    conv = tf.layers.conv1d(\n",
        "        inputs=dropout_emb,\n",
        "        filters=32,\n",
        "        kernel_size=3,\n",
        "        padding=\"same\",\n",
        "        activation=tf.nn.relu)\n",
        "    \n",
        "    # Global Max Pooling\n",
        "    pool = tf.reduce_max(input_tensor=conv, axis=1)\n",
        "    \n",
        "    hidden = tf.layers.dense(inputs=pool, units=250, activation=tf.nn.relu)\n",
        "    \n",
        "    dropout_hidden = tf.layers.dropout(inputs=hidden, \n",
        "                                       rate=0.2, \n",
        "                                       training=training)\n",
        "    \n",
        "    logits = tf.layers.dense(inputs=dropout_hidden, units=1)\n",
        "    \n",
        "    # This will be None when predicting\n",
        "    if labels is not None:\n",
        "        labels = tf.reshape(labels, [-1, 1])\n",
        "        \n",
        "\n",
        "    optimizer = tf.train.AdamOptimizer()\n",
        "    \n",
        "    def _train_op_fn(loss):\n",
        "        return optimizer.minimize(\n",
        "            loss=loss,\n",
        "            global_step=tf.train.get_global_step())\n",
        "\n",
        "    return head.create_estimator_spec(\n",
        "        features=features,\n",
        "        labels=labels,\n",
        "        mode=mode,\n",
        "        logits=logits, \n",
        "        train_op_fn=_train_op_fn)\n",
        "  \n",
        "params = {'embedding_initializer': tf.random_uniform_initializer(-1.0, 1.0)}\n",
        "cnn_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn,\n",
        "                                        model_dir=os.path.join(model_dir, 'cnn'),\n",
        "                                        params=params)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpfk_swc9j/cnn', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa24c2d57b8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OJM1sInMqass",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9623
        },
        "outputId": "97efcc5a-718a-40be-d55f-bf7b12b03aed"
      },
      "cell_type": "code",
      "source": [
        "def my_initializer(shape=None, dtype=tf.float32, partition_info=None):\n",
        "    assert dtype is tf.float32\n",
        "    return embedding_matrix\n",
        "\n",
        "params = {'embedding_initializer': my_initializer}\n",
        "cnn_pretrained_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn,\n",
        "                                        model_dir=os.path.join(model_dir, 'cnn_pretrained'),\n",
        "                                        params=params)\n",
        "train_and_evaluate(cnn_pretrained_classifier)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpfk_swc9j/cnn_pretrained', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa24c32fe48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From <ipython-input-60-227e8df9c3cd>:11: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n",
            "WARNING:tensorflow:From <ipython-input-60-227e8df9c3cd>:18: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.conv1d instead.\n",
            "WARNING:tensorflow:From <ipython-input-60-227e8df9c3cd>:23: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/canned/head.py:436: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpfk_swc9j/cnn_pretrained/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.73409957, step = 0\n",
            "INFO:tensorflow:global_step/sec: 30.1364\n",
            "INFO:tensorflow:loss = 0.5088071, step = 100 (3.323 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7657\n",
            "INFO:tensorflow:loss = 0.44101617, step = 200 (2.960 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.6233\n",
            "INFO:tensorflow:loss = 0.44555274, step = 300 (2.972 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.8021\n",
            "INFO:tensorflow:loss = 0.51293, step = 400 (2.960 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.0987\n",
            "INFO:tensorflow:loss = 0.47165382, step = 500 (2.932 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.3699\n",
            "INFO:tensorflow:loss = 0.50139403, step = 600 (2.999 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.897\n",
            "INFO:tensorflow:loss = 0.496469, step = 700 (2.953 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.8335\n",
            "INFO:tensorflow:loss = 0.52519774, step = 800 (2.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.6166\n",
            "INFO:tensorflow:loss = 0.5282182, step = 900 (2.973 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.4967\n",
            "INFO:tensorflow:loss = 0.48520434, step = 1000 (2.987 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.8526\n",
            "INFO:tensorflow:loss = 0.42829654, step = 1100 (2.953 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.6794\n",
            "INFO:tensorflow:loss = 0.52340585, step = 1200 (2.971 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.4187\n",
            "INFO:tensorflow:loss = 0.5023522, step = 1300 (2.992 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.6328\n",
            "INFO:tensorflow:loss = 0.45017326, step = 1400 (2.970 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7662\n",
            "INFO:tensorflow:loss = 0.48192772, step = 1500 (2.963 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.8951\n",
            "INFO:tensorflow:loss = 0.44698516, step = 1600 (2.951 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.953\n",
            "INFO:tensorflow:loss = 0.45056394, step = 1700 (2.947 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.6761\n",
            "INFO:tensorflow:loss = 0.5251917, step = 1800 (2.969 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.6976\n",
            "INFO:tensorflow:loss = 0.5664879, step = 1900 (2.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.8758\n",
            "INFO:tensorflow:loss = 0.39930266, step = 2000 (2.956 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.9693\n",
            "INFO:tensorflow:loss = 0.5456528, step = 2100 (2.944 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.5959\n",
            "INFO:tensorflow:loss = 0.44366467, step = 2200 (2.972 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.1288\n",
            "INFO:tensorflow:loss = 0.41804555, step = 2300 (2.936 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.8638\n",
            "INFO:tensorflow:loss = 0.37290442, step = 2400 (2.951 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.0992\n",
            "INFO:tensorflow:loss = 0.5823546, step = 2500 (2.932 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.2779\n",
            "INFO:tensorflow:loss = 0.4502098, step = 2600 (3.006 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.2155\n",
            "INFO:tensorflow:loss = 0.4556123, step = 2700 (2.919 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.9616\n",
            "INFO:tensorflow:loss = 0.46508065, step = 2800 (2.948 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.4196\n",
            "INFO:tensorflow:loss = 0.4202405, step = 2900 (2.993 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.839\n",
            "INFO:tensorflow:loss = 0.4843412, step = 3000 (2.951 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7589\n",
            "INFO:tensorflow:loss = 0.48540947, step = 3100 (2.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7041\n",
            "INFO:tensorflow:loss = 0.4692241, step = 3200 (2.971 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.3398\n",
            "INFO:tensorflow:loss = 0.4792655, step = 3300 (2.916 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.6761\n",
            "INFO:tensorflow:loss = 0.61204857, step = 3400 (2.961 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7819\n",
            "INFO:tensorflow:loss = 0.4045301, step = 3500 (2.960 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.5689\n",
            "INFO:tensorflow:loss = 0.414094, step = 3600 (2.982 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.8113\n",
            "INFO:tensorflow:loss = 0.4697624, step = 3700 (2.958 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.6842\n",
            "INFO:tensorflow:loss = 0.35523558, step = 3800 (2.965 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.8823\n",
            "INFO:tensorflow:loss = 0.5226968, step = 3900 (2.954 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.9324\n",
            "INFO:tensorflow:loss = 0.50230426, step = 4000 (2.947 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.1766\n",
            "INFO:tensorflow:loss = 0.38853198, step = 4100 (2.929 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.8255\n",
            "INFO:tensorflow:loss = 0.34455568, step = 4200 (2.952 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7447\n",
            "INFO:tensorflow:loss = 0.4730287, step = 4300 (2.966 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.6132\n",
            "INFO:tensorflow:loss = 0.44526473, step = 4400 (2.976 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.3587\n",
            "INFO:tensorflow:loss = 0.7611642, step = 4500 (2.993 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.8462\n",
            "INFO:tensorflow:loss = 0.4857946, step = 4600 (2.958 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.6558\n",
            "INFO:tensorflow:loss = 0.4979273, step = 4700 (2.973 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7719\n",
            "INFO:tensorflow:loss = 0.42842814, step = 4800 (2.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.065\n",
            "INFO:tensorflow:loss = 0.51230067, step = 4900 (2.931 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.5734\n",
            "INFO:tensorflow:loss = 0.4741803, step = 5000 (2.982 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.8519\n",
            "INFO:tensorflow:loss = 0.48849547, step = 5100 (2.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.0378\n",
            "INFO:tensorflow:loss = 0.45008814, step = 5200 (2.936 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.1429\n",
            "INFO:tensorflow:loss = 0.533137, step = 5300 (2.930 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.647\n",
            "INFO:tensorflow:loss = 0.4437443, step = 5400 (2.969 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.9421\n",
            "INFO:tensorflow:loss = 0.65243196, step = 5500 (2.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.227\n",
            "INFO:tensorflow:loss = 0.49094734, step = 5600 (2.919 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.858\n",
            "INFO:tensorflow:loss = 0.5450056, step = 5700 (2.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.0289\n",
            "INFO:tensorflow:loss = 0.59156156, step = 5800 (2.939 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.1839\n",
            "INFO:tensorflow:loss = 0.4613522, step = 5900 (2.926 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.1011\n",
            "INFO:tensorflow:loss = 0.5284455, step = 6000 (2.930 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7253\n",
            "INFO:tensorflow:loss = 0.4301687, step = 6100 (2.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.5543\n",
            "INFO:tensorflow:loss = 0.41542378, step = 6200 (2.984 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.8619\n",
            "INFO:tensorflow:loss = 0.5456632, step = 6300 (2.954 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.6365\n",
            "INFO:tensorflow:loss = 0.47928533, step = 6400 (2.968 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7962\n",
            "INFO:tensorflow:loss = 0.5143352, step = 6500 (2.960 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.6233\n",
            "INFO:tensorflow:loss = 0.5111362, step = 6600 (2.888 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.3968\n",
            "INFO:tensorflow:loss = 0.44426277, step = 6700 (2.910 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.9082\n",
            "INFO:tensorflow:loss = 0.43166107, step = 6800 (2.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.6596\n",
            "INFO:tensorflow:loss = 0.6524405, step = 6900 (2.971 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.855\n",
            "INFO:tensorflow:loss = 0.5216844, step = 7000 (2.954 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7862\n",
            "INFO:tensorflow:loss = 0.51987964, step = 7100 (2.960 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.2069\n",
            "INFO:tensorflow:loss = 0.4596984, step = 7200 (2.920 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7051\n",
            "INFO:tensorflow:loss = 0.481256, step = 7300 (2.967 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.8624\n",
            "INFO:tensorflow:loss = 0.44500557, step = 7400 (2.952 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7945\n",
            "INFO:tensorflow:loss = 0.42502528, step = 7500 (2.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 32.9261\n",
            "INFO:tensorflow:loss = 0.46160647, step = 7600 (3.033 sec)\n",
            "INFO:tensorflow:global_step/sec: 26.7609\n",
            "INFO:tensorflow:loss = 0.59884965, step = 7700 (3.738 sec)\n",
            "INFO:tensorflow:global_step/sec: 26.9727\n",
            "INFO:tensorflow:loss = 0.4882887, step = 7800 (3.706 sec)\n",
            "INFO:tensorflow:global_step/sec: 26.5989\n",
            "INFO:tensorflow:loss = 0.57593364, step = 7900 (3.768 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.9595\n",
            "INFO:tensorflow:loss = 0.41577402, step = 8000 (3.568 sec)\n",
            "INFO:tensorflow:global_step/sec: 26.5398\n",
            "INFO:tensorflow:loss = 0.45799506, step = 8100 (3.773 sec)\n",
            "INFO:tensorflow:global_step/sec: 26.3354\n",
            "INFO:tensorflow:loss = 0.51780313, step = 8200 (3.804 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.0012\n",
            "INFO:tensorflow:loss = 0.48696938, step = 8300 (3.020 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.2954\n",
            "INFO:tensorflow:loss = 0.44428816, step = 8400 (2.914 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.016\n",
            "INFO:tensorflow:loss = 0.5318495, step = 8500 (2.940 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.9807\n",
            "INFO:tensorflow:loss = 0.47327605, step = 8600 (2.946 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.9026\n",
            "INFO:tensorflow:loss = 0.42040524, step = 8700 (2.947 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7586\n",
            "INFO:tensorflow:loss = 0.40807334, step = 8800 (2.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.4444\n",
            "INFO:tensorflow:loss = 0.44562548, step = 8900 (2.991 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7847\n",
            "INFO:tensorflow:loss = 0.37904313, step = 9000 (2.961 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.8167\n",
            "INFO:tensorflow:loss = 0.47026923, step = 9100 (2.954 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.2095\n",
            "INFO:tensorflow:loss = 0.49899915, step = 9200 (3.012 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.3703\n",
            "INFO:tensorflow:loss = 0.47407943, step = 9300 (2.996 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.036\n",
            "INFO:tensorflow:loss = 0.42416906, step = 9400 (2.941 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.1138\n",
            "INFO:tensorflow:loss = 0.46756047, step = 9500 (2.928 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.8735\n",
            "INFO:tensorflow:loss = 0.38729447, step = 9600 (2.953 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.9344\n",
            "INFO:tensorflow:loss = 0.48510075, step = 9700 (2.949 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.9115\n",
            "INFO:tensorflow:loss = 0.48685265, step = 9800 (2.947 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.8875\n",
            "INFO:tensorflow:loss = 0.48809665, step = 9900 (2.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.6851\n",
            "INFO:tensorflow:loss = 0.534506, step = 10000 (2.969 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.775\n",
            "INFO:tensorflow:loss = 0.5357189, step = 10100 (2.958 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.0736\n",
            "INFO:tensorflow:loss = 0.5301887, step = 10200 (2.940 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.6081\n",
            "INFO:tensorflow:loss = 0.45794937, step = 10300 (2.974 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.6922\n",
            "INFO:tensorflow:loss = 0.626682, step = 10400 (2.970 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.9528\n",
            "INFO:tensorflow:loss = 0.4828155, step = 10500 (2.941 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.8946\n",
            "INFO:tensorflow:loss = 0.53490347, step = 10600 (2.954 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.9178\n",
            "INFO:tensorflow:loss = 0.4735682, step = 10700 (2.947 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.919\n",
            "INFO:tensorflow:loss = 0.45980462, step = 10800 (2.949 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.5659\n",
            "INFO:tensorflow:loss = 0.45859706, step = 10900 (2.979 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.9498\n",
            "INFO:tensorflow:loss = 0.5364121, step = 11000 (2.942 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7758\n",
            "INFO:tensorflow:loss = 0.52581155, step = 11100 (2.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7658\n",
            "INFO:tensorflow:loss = 0.46076548, step = 11200 (2.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7379\n",
            "INFO:tensorflow:loss = 0.4827828, step = 11300 (2.967 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.6558\n",
            "INFO:tensorflow:loss = 0.46033624, step = 11400 (2.967 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.721\n",
            "INFO:tensorflow:loss = 0.39015058, step = 11500 (2.967 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.5849\n",
            "INFO:tensorflow:loss = 0.46745342, step = 11600 (2.974 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.866\n",
            "INFO:tensorflow:loss = 0.5340096, step = 11700 (2.954 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.4463\n",
            "INFO:tensorflow:loss = 0.4847021, step = 11800 (2.904 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7811\n",
            "INFO:tensorflow:loss = 0.45776394, step = 11900 (2.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.4635\n",
            "INFO:tensorflow:loss = 0.44276705, step = 12000 (2.989 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.0693\n",
            "INFO:tensorflow:loss = 0.469459, step = 12100 (3.023 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.9402\n",
            "INFO:tensorflow:loss = 0.51654553, step = 12200 (2.944 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7773\n",
            "INFO:tensorflow:loss = 0.430713, step = 12300 (2.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.1354\n",
            "INFO:tensorflow:loss = 0.46169433, step = 12400 (2.935 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.735\n",
            "INFO:tensorflow:loss = 0.45586693, step = 12500 (2.961 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.3518\n",
            "INFO:tensorflow:loss = 0.48438865, step = 12600 (2.913 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.8408\n",
            "INFO:tensorflow:loss = 0.443235, step = 12700 (2.956 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.8952\n",
            "INFO:tensorflow:loss = 0.5565833, step = 12800 (2.949 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7126\n",
            "INFO:tensorflow:loss = 0.5216028, step = 12900 (2.967 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.2431\n",
            "INFO:tensorflow:loss = 0.42850688, step = 13000 (3.007 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.2428\n",
            "INFO:tensorflow:loss = 0.5307062, step = 13100 (3.006 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.6504\n",
            "INFO:tensorflow:loss = 0.48179132, step = 13200 (2.974 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.3227\n",
            "INFO:tensorflow:loss = 0.4702527, step = 13300 (2.911 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7675\n",
            "INFO:tensorflow:loss = 0.35709327, step = 13400 (2.961 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.9091\n",
            "INFO:tensorflow:loss = 0.45630088, step = 13500 (2.949 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.3269\n",
            "INFO:tensorflow:loss = 0.47673312, step = 13600 (2.915 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.0934\n",
            "INFO:tensorflow:loss = 0.5284653, step = 13700 (3.024 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7064\n",
            "INFO:tensorflow:loss = 0.500052, step = 13800 (2.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.6473\n",
            "INFO:tensorflow:loss = 0.5562543, step = 13900 (2.975 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.8597\n",
            "INFO:tensorflow:loss = 0.4860996, step = 14000 (2.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.9774\n",
            "INFO:tensorflow:loss = 0.48919818, step = 14100 (2.941 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7949\n",
            "INFO:tensorflow:loss = 0.4883188, step = 14200 (2.960 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.0886\n",
            "INFO:tensorflow:loss = 0.4813795, step = 14300 (2.932 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.1646\n",
            "INFO:tensorflow:loss = 0.4885419, step = 14400 (2.926 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.6139\n",
            "INFO:tensorflow:loss = 0.48585322, step = 14500 (2.974 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.9062\n",
            "INFO:tensorflow:loss = 0.42135125, step = 14600 (2.954 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.0957\n",
            "INFO:tensorflow:loss = 0.48482883, step = 14700 (2.932 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.4786\n",
            "INFO:tensorflow:loss = 0.5329856, step = 14800 (2.986 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7965\n",
            "INFO:tensorflow:loss = 0.56189245, step = 14900 (2.958 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.9795\n",
            "INFO:tensorflow:loss = 0.6600584, step = 15000 (2.945 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.8256\n",
            "INFO:tensorflow:loss = 0.47078678, step = 15100 (2.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.0343\n",
            "INFO:tensorflow:loss = 0.5172334, step = 15200 (2.936 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.0536\n",
            "INFO:tensorflow:loss = 0.3597915, step = 15300 (2.941 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7118\n",
            "INFO:tensorflow:loss = 0.4601679, step = 15400 (2.968 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.6267\n",
            "INFO:tensorflow:loss = 0.5894512, step = 15500 (2.970 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.5974\n",
            "INFO:tensorflow:loss = 0.50580984, step = 15600 (2.978 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.5821\n",
            "INFO:tensorflow:loss = 0.4589038, step = 15700 (2.974 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.3893\n",
            "INFO:tensorflow:loss = 0.50022817, step = 15800 (2.999 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.724\n",
            "INFO:tensorflow:loss = 0.47026673, step = 15900 (2.961 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.4702\n",
            "INFO:tensorflow:loss = 0.44501314, step = 16000 (2.992 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.5192\n",
            "INFO:tensorflow:loss = 0.4737353, step = 16100 (2.980 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.2338\n",
            "INFO:tensorflow:loss = 0.32406375, step = 16200 (3.013 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.329\n",
            "INFO:tensorflow:loss = 0.39547208, step = 16300 (2.994 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7333\n",
            "INFO:tensorflow:loss = 0.46131948, step = 16400 (2.965 sec)\n",
            "INFO:tensorflow:global_step/sec: 32.9876\n",
            "INFO:tensorflow:loss = 0.5016335, step = 16500 (3.036 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.3772\n",
            "INFO:tensorflow:loss = 0.47340408, step = 16600 (2.991 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.5819\n",
            "INFO:tensorflow:loss = 0.54461, step = 16700 (2.978 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.0064\n",
            "INFO:tensorflow:loss = 0.45617783, step = 16800 (2.945 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.1093\n",
            "INFO:tensorflow:loss = 0.46201622, step = 16900 (2.929 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7426\n",
            "INFO:tensorflow:loss = 0.4827899, step = 17000 (2.966 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.2452\n",
            "INFO:tensorflow:loss = 0.388908, step = 17100 (2.919 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.2985\n",
            "INFO:tensorflow:loss = 0.4295848, step = 17200 (3.004 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.2652\n",
            "INFO:tensorflow:loss = 0.4737612, step = 17300 (3.005 sec)\n",
            "INFO:tensorflow:global_step/sec: 31.9617\n",
            "INFO:tensorflow:loss = 0.54277986, step = 17400 (3.130 sec)\n",
            "INFO:tensorflow:global_step/sec: 29.7092\n",
            "INFO:tensorflow:loss = 0.574583, step = 17500 (3.366 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.8546\n",
            "INFO:tensorflow:loss = 0.4265938, step = 17600 (2.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.9083\n",
            "INFO:tensorflow:loss = 0.55896574, step = 17700 (2.947 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.0665\n",
            "INFO:tensorflow:loss = 0.45150664, step = 17800 (2.936 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.984\n",
            "INFO:tensorflow:loss = 0.5114825, step = 17900 (2.948 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7741\n",
            "INFO:tensorflow:loss = 0.5921904, step = 18000 (2.963 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.6723\n",
            "INFO:tensorflow:loss = 0.42984182, step = 18100 (2.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.4737\n",
            "INFO:tensorflow:loss = 0.39702296, step = 18200 (2.905 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.275\n",
            "INFO:tensorflow:loss = 0.46062684, step = 18300 (2.919 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.0515\n",
            "INFO:tensorflow:loss = 0.4147051, step = 18400 (2.932 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.9936\n",
            "INFO:tensorflow:loss = 0.42484745, step = 18500 (2.941 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.6964\n",
            "INFO:tensorflow:loss = 0.47138068, step = 18600 (2.970 sec)\n",
            "INFO:tensorflow:global_step/sec: 30.7047\n",
            "INFO:tensorflow:loss = 0.48822808, step = 18700 (3.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.0689\n",
            "INFO:tensorflow:loss = 0.5327895, step = 18800 (2.938 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.8918\n",
            "INFO:tensorflow:loss = 0.5605262, step = 18900 (2.948 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.688\n",
            "INFO:tensorflow:loss = 0.39662603, step = 19000 (2.973 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.9531\n",
            "INFO:tensorflow:loss = 0.3891096, step = 19100 (2.940 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.1314\n",
            "INFO:tensorflow:loss = 0.45356062, step = 19200 (2.930 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.6092\n",
            "INFO:tensorflow:loss = 0.44130322, step = 19300 (2.979 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7648\n",
            "INFO:tensorflow:loss = 0.5398339, step = 19400 (2.958 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.8186\n",
            "INFO:tensorflow:loss = 0.4320671, step = 19500 (2.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.832\n",
            "INFO:tensorflow:loss = 0.41722146, step = 19600 (2.952 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.8422\n",
            "INFO:tensorflow:loss = 0.5198357, step = 19700 (2.957 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.8997\n",
            "INFO:tensorflow:loss = 0.45597604, step = 19800 (2.950 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.8059\n",
            "INFO:tensorflow:loss = 0.42394876, step = 19900 (2.959 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.7116\n",
            "INFO:tensorflow:loss = 0.4416113, step = 20000 (2.962 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 20071 into /tmp/tmpfk_swc9j/cnn_pretrained/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 32.3555\n",
            "INFO:tensorflow:loss = 0.51095104, step = 20100 (3.095 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.2137\n",
            "INFO:tensorflow:loss = 0.5009033, step = 20200 (3.009 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.5266\n",
            "INFO:tensorflow:loss = 0.4431681, step = 20300 (2.984 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.9851\n",
            "INFO:tensorflow:loss = 0.48697522, step = 20400 (2.941 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.2378\n",
            "INFO:tensorflow:loss = 0.41365564, step = 20500 (2.920 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.4565\n",
            "INFO:tensorflow:loss = 0.45113468, step = 20600 (2.900 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.3493\n",
            "INFO:tensorflow:loss = 0.50105876, step = 20700 (2.916 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.7006\n",
            "INFO:tensorflow:loss = 0.457636, step = 20800 (2.880 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.8011\n",
            "INFO:tensorflow:loss = 0.42912576, step = 20900 (2.872 sec)\n",
            "INFO:tensorflow:global_step/sec: 33.3108\n",
            "INFO:tensorflow:loss = 0.53076667, step = 21000 (3.001 sec)\n",
            "INFO:tensorflow:global_step/sec: 29.1981\n",
            "INFO:tensorflow:loss = 0.44420967, step = 21100 (3.425 sec)\n",
            "INFO:tensorflow:global_step/sec: 27.4001\n",
            "INFO:tensorflow:loss = 0.4293096, step = 21200 (3.649 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.7117\n",
            "INFO:tensorflow:loss = 0.54642457, step = 21300 (3.483 sec)\n",
            "INFO:tensorflow:global_step/sec: 30.1265\n",
            "INFO:tensorflow:loss = 0.48747244, step = 21400 (3.319 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.2231\n",
            "INFO:tensorflow:loss = 0.42986423, step = 21500 (2.925 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.4368\n",
            "INFO:tensorflow:loss = 0.4748082, step = 21600 (2.903 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.4754\n",
            "INFO:tensorflow:loss = 0.5277011, step = 21700 (2.902 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.2101\n",
            "INFO:tensorflow:loss = 0.5026434, step = 21800 (2.921 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.3336\n",
            "INFO:tensorflow:loss = 0.5897591, step = 21900 (2.916 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.4158\n",
            "INFO:tensorflow:loss = 0.42357096, step = 22000 (2.906 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.1402\n",
            "INFO:tensorflow:loss = 0.48558804, step = 22100 (2.927 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.6482\n",
            "INFO:tensorflow:loss = 0.50098, step = 22200 (2.889 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.5737\n",
            "INFO:tensorflow:loss = 0.47145703, step = 22300 (2.891 sec)\n",
            "INFO:tensorflow:global_step/sec: 32.215\n",
            "INFO:tensorflow:loss = 0.4013482, step = 22400 (3.106 sec)\n",
            "INFO:tensorflow:global_step/sec: 32.4104\n",
            "INFO:tensorflow:loss = 0.48999155, step = 22500 (3.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.4038\n",
            "INFO:tensorflow:loss = 0.48376855, step = 22600 (2.903 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.2094\n",
            "INFO:tensorflow:loss = 0.5763429, step = 22700 (2.923 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.0057\n",
            "INFO:tensorflow:loss = 0.46149594, step = 22800 (2.942 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.3556\n",
            "INFO:tensorflow:loss = 0.4754545, step = 22900 (2.910 sec)\n",
            "INFO:tensorflow:global_step/sec: 34.0113\n",
            "INFO:tensorflow:loss = 0.4984215, step = 23000 (2.944 sec)\n",
            "INFO:tensorflow:global_step/sec: 28.1512\n",
            "INFO:tensorflow:loss = 0.5304423, step = 23100 (3.555 sec)\n",
            "INFO:tensorflow:global_step/sec: 19.9095\n",
            "INFO:tensorflow:loss = 0.3713548, step = 23200 (5.023 sec)\n",
            "INFO:tensorflow:global_step/sec: 18.6135\n",
            "INFO:tensorflow:loss = 0.5178127, step = 23300 (5.368 sec)\n",
            "INFO:tensorflow:global_step/sec: 18.3275\n",
            "INFO:tensorflow:loss = 0.6925811, step = 23400 (5.457 sec)\n",
            "INFO:tensorflow:global_step/sec: 18.4449\n",
            "INFO:tensorflow:loss = 0.5291106, step = 23500 (5.424 sec)\n",
            "INFO:tensorflow:global_step/sec: 18.1462\n",
            "INFO:tensorflow:loss = 0.4725901, step = 23600 (5.507 sec)\n",
            "INFO:tensorflow:global_step/sec: 18.7173\n",
            "INFO:tensorflow:loss = 0.51593435, step = 23700 (5.341 sec)\n",
            "INFO:tensorflow:global_step/sec: 18.5878\n",
            "INFO:tensorflow:loss = 0.44340143, step = 23800 (5.384 sec)\n",
            "INFO:tensorflow:global_step/sec: 18.3295\n",
            "INFO:tensorflow:loss = 0.49974212, step = 23900 (5.458 sec)\n",
            "INFO:tensorflow:global_step/sec: 18.4328\n",
            "INFO:tensorflow:loss = 0.49875447, step = 24000 (5.426 sec)\n",
            "INFO:tensorflow:global_step/sec: 18.3449\n",
            "INFO:tensorflow:loss = 0.45334664, step = 24100 (5.448 sec)\n",
            "INFO:tensorflow:global_step/sec: 18.5089\n",
            "INFO:tensorflow:loss = 0.44083333, step = 24200 (5.404 sec)\n",
            "INFO:tensorflow:global_step/sec: 18.6107\n",
            "INFO:tensorflow:loss = 0.47059512, step = 24300 (5.375 sec)\n",
            "INFO:tensorflow:global_step/sec: 18.4825\n",
            "INFO:tensorflow:loss = 0.42938995, step = 24400 (5.411 sec)\n",
            "INFO:tensorflow:global_step/sec: 18.645\n",
            "INFO:tensorflow:loss = 0.45510375, step = 24500 (5.363 sec)\n",
            "INFO:tensorflow:global_step/sec: 18.6092\n",
            "INFO:tensorflow:loss = 0.5011239, step = 24600 (5.372 sec)\n",
            "INFO:tensorflow:global_step/sec: 18.5514\n",
            "INFO:tensorflow:loss = 0.53215814, step = 24700 (5.388 sec)\n",
            "INFO:tensorflow:global_step/sec: 18.4248\n",
            "INFO:tensorflow:loss = 0.57372206, step = 24800 (5.425 sec)\n",
            "INFO:tensorflow:global_step/sec: 18.1977\n",
            "INFO:tensorflow:loss = 0.46974656, step = 24900 (5.498 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 25000 into /tmp/tmpfk_swc9j/cnn_pretrained/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.48686215.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
            "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-03-21T10:13:55Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpfk_swc9j/cnn_pretrained/model.ckpt-25000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-03-21-10:13:56\n",
            "INFO:tensorflow:Saving dict for global step 25000: accuracy = 0.79141104, accuracy_baseline = 0.79141104, auc = 0.5, auc_precision_recall = 0.8957055, average_loss = 0.51278603, global_step = 25000, label/mean = 0.79141104, loss = 0.5247635, precision = 0.79141104, prediction/mean = 0.8063888, recall = 1.0\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 25000: /tmp/tmpfk_swc9j/cnn_pretrained/model.ckpt-25000\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpfk_swc9j/cnn_pretrained/model.ckpt-25000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-b756eb8a75dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                                         \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cnn_pretrained'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                         params=params)\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_pretrained_classifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-59-721696cee597>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(classifier)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Add a PR summary in addition to the summaries that the classifier writes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpr_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision_recall'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_thresholds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'eval'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'summary_lib' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "2PLPqWAOsV-i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
